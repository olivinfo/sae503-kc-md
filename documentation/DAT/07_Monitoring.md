# 6. Monitoring et Maintenance

## 6.1 Surveillance

### 6.1.1 Surveillance des services

#### 6.1.1.1 Commandes kubectl

```bash
# Surveillance des pods
kubectl get pods -n haddock -w

# Surveillance des √©v√©nements
kubectl get events -n haddock --sort-by='.metadata.creationTimestamp'

# Surveillance des ressources
kubectl top pods -n haddock
kubectl top nodes

# Surveillance des d√©ploiements
kubectl get deployments -n haddock
kubectl describe deployment <nom-du-deployment> -n haddock
```

#### 6.1.1.2 Commandes Docker

```bash
# Surveillance des conteneurs
docker ps
watch docker ps

# Surveillance des ressources
docker stats

# Surveillance des logs
docker logs -f <nom-du-conteneur>
```

### 6.1.2 Dashboard Traefik

**Acc√®s** : <http://localhost:8080/dashboard/>

**Fonctionnalit√©s** :

- Visualisation des routes configur√©es
- Statistiques de trafic
- √âtat des services
- Configuration actuelle

**Configuration** :

```yaml
# Dans le fichier docker-compose.yaml
services:
  traefik:
    # ...
    command:
      - "--api.insecure=true"  # Active le dashboard
      - "--api.dashboard=true"
    ports:
      - "8080:8080"  # Port du dashboard
```

### 6.1.3 Surveillance des endpoints

**Health checks** :

```bash
# V√©rification de sant√© des services
curl http://localhost/quotes/health
curl http://localhost/users/health
curl http://localhost/search/health

# Script de surveillance
while true; do
    echo "$(date) - Quotes: $(curl -s http://localhost/quotes/health | jq -r '.message')"
    echo "$(date) - Users: $(curl -s http://localhost/users/health | jq -r '.message')"
    echo "$(date) - Search: $(curl -s http://localhost/search/health | jq -r '.message')"
    sleep 5
end
```

## 6.2 Journalisation

### 6.2.1 Journalisation des applications

#### 6.2.1.1 Configuration Flask

```python
import logging
from logging.handlers import RotatingFileHandler

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Handler pour les fichiers
file_handler = RotatingFileHandler(
    'app.log',
    maxBytes=1024 * 1024 * 5,  # 5 MB
    backupCount=5
)
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
))

# Ajout du handler
app.logger.addHandler(file_handler)

# Exemple d'utilisation
@app.route('/quotes', methods=['GET'])
def get_quotes():
    app.logger.info('R√©cup√©ration des citations')
    try:
        quotes = redis_client.smembers("quotes")
        app.logger.debug(f'Trouv√© {len(quotes)} citations')
        return jsonify([redis_client.hgetall(quote) for quote in quotes]), 200
    except Exception as e:
        app.logger.error(f'Erreur lors de la r√©cup√©ration des citations: {str(e)}')
        return jsonify({"error": "Internal server error"}), 500
```

#### 6.2.1.2 Niveaux de journalisation

| Niveau       | Utilisation                                   |
|--------------|-----------------------------------------------|
| DEBUG        | Informations de d√©bogage d√©taill√©es           |
| INFO         | Informations g√©n√©rales sur le fonctionnement  |
| WARNING      | Avertissements et situations inhabituelles    |
| ERROR        | Erreurs qui affectent une op√©ration           |
| CRITICAL     | Erreurs critiques n√©cessitant une intervention|

### 6.2.2 Journalisation Kubernetes

#### 6.2.2.1 R√©cup√©ration des logs

```bash
# Logs d'un pod sp√©cifique
kubectl logs <nom-du-pod> -n haddock

# Logs en temps r√©el
kubectl logs -f <nom-du-pod> -n haddock

# Logs des conteneurs pr√©c√©dents
kubectl logs <nom-du-pod> -n haddock --previous

# Logs avec s√©lection
kubectl logs -l app=quotes-service -n haddock

# Logs avec timestamp
kubectl logs --timestamps <nom-du-pod> -n haddock
```

#### 6.2.2.2 Journalisation centralis√©e (√† impl√©menter)

**Options** :

1. **EFK Stack** (Elasticsearch, Fluentd, Kibana)
2. **Loki + Promtail + Grafana**
3. **Fluent Bit + Elasticsearch**

**Exemple de configuration Fluentd** :

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: haddock
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch
      port 9200
      logstash_format true
      logstash_prefix kubernetes
      include_tag_key true
      type_name fluentd
    </match>
```

### 6.2.3 Rotation des logs

#### 6.2.3.1 Configuration dans les conteneurs

```dockerfile
# Dans le Dockerfile
RUN apt-get update && apt-get install -y logrotate

COPY logrotate.conf /etc/logrotate.conf
COPY logrotate.d/app /etc/logrotate.d/app

# Configuration logrotate
# /etc/logrotate.d/app
/app/logs/*.log {
    daily
    missingok
    rotate 7
    compress
    delaycompress
    notifempty
    copytruncate
}
```

#### 6.2.3.2 Rotation manuelle

```bash
# Rotation manuelle des logs
logrotate -f /etc/logrotate.conf

# V√©rification
ls -la /app/logs/
```

## 6.3 Maintenance

### 6.3.1 Maintenance pr√©ventive

#### 6.3.1.1 Plan de maintenance

| T√¢che                          | Fr√©quence       | Responsable      |
|--------------------------------|-----------------|------------------|
| V√©rification des logs          | Quotidienne     | √âquipe DevOps    |
| Mise √† jour des d√©pendances    | Hebdomadaire    | √âquipe Dev       |
| Sauvegarde des donn√©es         | Quotidienne     | √âquipe DevOps    |
| Scan de s√©curit√©               | Hebdomadaire    | √âquipe S√©curit√©  |
| V√©rification des performances  | Quotidienne     | √âquipe DevOps    |
| Nettoyage des ressources       | Mensuelle       | √âquipe DevOps    |

#### 6.3.1.2 Checklist de maintenance

```markdown
- [ ] V√©rifier l'√©tat des pods Kubernetes
- [ ] V√©rifier les logs des applications
- [ ] V√©rifier l'espace disque
- [ ] V√©rifier la m√©moire disponible
- [ ] V√©rifier les connexions Redis
- [ ] Ex√©cuter les tests de sant√©
- [ ] V√©rifier les sauvegardes
- [ ] Scanner les vuln√©rabilit√©s
- [ ] Mettre √† jour la documentation
```

### 6.3.2 Mises √† jour

#### 6.3.2.1 Processus de mise √† jour

1. **Planification** : Identifier les composants √† mettre √† jour
2. **Test** : Tester les mises √† jour dans un environnement de staging
3. **Sauvegarde** : Sauvegarder les donn√©es et configurations
4. **D√©ploiement** : Appliquer les mises √† jour en production
5. **V√©rification** : V√©rifier le bon fonctionnement
6. **Documentation** : Mettre √† jour la documentation

#### 6.3.2.2 Mise √† jour des images Docker

```bash
# Mise √† jour d'une image
docker pull redis:8

# Reconstruction des images personnalis√©es
docker build -t kitami1/sae503-quotes:v1.1.0 -f citations_haddock/quotes/Dockerfile citations_haddock

# Mise √† jour du d√©ploiement
kubectl set image deployment/quotes-service quotes-service=kitami1/sae503-quotes:v1.1.0 -n haddock
```

### 6.3.3 Nettoyage

#### 6.3.3.1 Nettoyage Kubernetes

```bash
# Suppression des pods termin√©s
kubectl delete pods --field-selector=status.phase==Succeeded -n haddock
kubectl delete pods --field-selector=status.phase==Failed -n haddock

# Nettoyage des images non utilis√©es
kubectl get images | grep none | awk '{print $1}' | xargs -I {} kubectl delete image {}

# Nettoyage des ressources inutilis√©es
kubectl delete --dry-run=client -o yaml $(kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found -n haddock) | kubectl delete -f -
```

#### 6.3.3.2 Nettoyage Docker

```bash
# Nettoyage des conteneurs
docker container prune

# Nettoyage des images
docker image prune -a

# Nettoyage des volumes
docker volume prune

# Nettoyage complet
docker system prune -a --volumes
```

## 6.4 Sauvegardes

### 6.4.1 Strat√©gie de sauvegarde

#### 6.4.1.1 Politique de sauvegarde

| Type de donn√©es       | Fr√©quence   | R√©tention | M√©thode                  |
|-----------------------|-------------|-----------|--------------------------|
| Donn√©es Redis         | Quotidienne | 7 jours   | Sauvegarde RDB           |
| Configurations K8s    | Quotidienne | 30 jours  | Export YAML              |
| Images Docker         | Hebdomadaire| 4 semaines| Registry priv√©           |
| Code source           | Continue    | Illimit√©e | GitHub                   |
| Logs                  | Quotidienne | 30 jours  | Archivage compress√©      |

#### 6.4.1.2 Plan de reprise d'activit√©

1. **RTO (Recovery Time Objective)** : 1 heure
2. **RPO (Recovery Point Objective)** : 24 heures
3. **Priorit√©** : Donn√©es > Configurations > Applications

### 6.4.2 Sauvegarde des donn√©es Redis

#### 6.4.2.1 Sauvegarde manuelle

```bash
# Sauvegarde RDB
kubectl exec -it <redis-pod> -n haddock -- redis-cli save
kubectl exec -it <redis-pod> -n haddock -- redis-cli bgsave

# Copie du fichier de sauvegarde
kubectl cp haddock/<redis-pod>:/data/dump.rdb ./backup/redis-$(date +%Y%m%d).rdb
```

#### 6.4.2.2 Sauvegarde automatique (√† impl√©menter)

```yaml
# CronJob Kubernetes pour sauvegarde automatique
apiVersion: batch/v1
kind: CronJob
metadata:
  name: redis-backup
  namespace: haddock
spec:
  schedule: "0 2 * * *"  # Tous les jours √† 2h
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: redis-backup
            image: redis:8
            command:
            - /bin/sh
            - -c
            - "redis-cli -h backend-redis save && cp /data/dump.rdb /backup/redis-$(date +%Y%m%d).rdb"
          restartPolicy: OnFailure
          volumes:
          - name: backup-volume
            persistentVolumeClaim:
              claimName: backup-pvc
```

### 6.4.3 Sauvegarde des configurations Kubernetes

#### 6.4.3.1 Export complet

```bash
# Sauvegarde de tous les objets Kubernetes
kubectl get all -n haddock -o yaml > backup/haddock-full-$(date +%Y%m%d).yaml

# Sauvegarde des objets sp√©cifiques
kubectl get deployments,services,ingress -n haddock -o yaml > backup/haddock-core-$(date +%Y%m%d).yaml

# Sauvegarde des secrets
kubectl get secrets -n haddock -o yaml > backup/haddock-secrets-$(date +%Y%m%d).yaml
```

#### 6.4.3.2 Restauration

```bash
# Restauration √† partir d'une sauvegarde
kubectl apply -f backup/haddock-full-20240101.yaml

# V√©rification
kubectl get all -n haddock
```

### 6.4.4 Sauvegarde du code source

#### 6.4.4.1 Strat√©gie Git

```bash
# Commit r√©gulier
git add .
git commit -m "Sauvegarde automatique - $(date +%Y%m%d)"
git push origin main

# Tag des versions importantes
git tag -a v1.0.0 -m "Version 1.0.0"
git push origin v1.0.0
```

#### 6.4.4.2 Archivage

```bash
# Cr√©ation d'une archive
tar -czvf sae503-backup-$(date +%Y%m%d).tar.gz .

# Chiffrement (optionnel)
gpg --encrypt --recipient user@example.com sae503-backup-$(date +%Y%m%d).tar.gz
```

## 6.5 Alertes et notifications

### 6.5.1 Configuration des alertes (√† impl√©menter)

#### 6.5.1.1 Alertes Kubernetes

```yaml
# Exemple de configuration avec Prometheus Operator
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: haddock-alerts
  namespace: haddock
spec:
  groups:
  - name: haddock.rules
    rules:
    - alert: PodDown
      expr: kube_pod_status_phase{phase="Running", namespace="haddock"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod {{ $labels.pod }} is down"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been down for more than 5 minutes"
    
    - alert: HighMemoryUsage
      expr: (sum(container_memory_working_set_bytes{namespace="haddock"}) by (pod) / sum(container_spec_memory_limit_bytes{namespace="haddock"}) by (pod)) * 100 > 80
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage in pod {{ $labels.pod }}"
        description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been using more than 80% of its memory limit for 10 minutes"
```

#### 6.5.1.2 Int√©gration avec des outils externes

**Options** :

1. **Slack** : Notifications via webhooks
2. **Email** : Envoi d'emails via SMTP
3. **PagerDuty** : Alertes professionnelles
4. **Discord** : Notifications pour les √©quipes

### 6.5.2 Journal des incidents

#### 6.5.2.1 Mod√®le de rapport d'incident

```markdown
# Rapport d'incident - [ID]

## R√©sum√©
- **Date** : [Date et heure]
- **Service affect√©** : [Nom du service]
- **Impact** : [Haut/Moyen/Faible]
- **Dur√©e** : [Dur√©e de l'incident]

## Chronologie
- [HH:MM] : D√©tection de l'incident
- [HH:MM] : D√©but de l'investigation
- [HH:MM] : Identification de la cause
- [HH:MM] : Application du correctif
- [HH:MM] : R√©solution compl√®te

## Cause racine
[Description d√©taill√©e de la cause]

## Actions correctives
1. [Action 1]
2. [Action 2]
3. [Action 3]

## Actions pr√©ventives
1. [Action 1]
2. [Action 2]
3. [Action 3]

## Responsables
- **D√©tection** : [Nom]
- **R√©solution** : [Nom]
- **Communication** : [Nom]

## Pi√®ces jointes
- [Logs pertinents]
- [Screenshots]
- [Autres preuves]
```

#### 6.5.2.2 Exemple de rapport

```markdown
# Rapport d'incident - INC-2024-001

## R√©sum√©
- **Date** : 2024-01-15 14:30:00
- **Service affect√©** : Quotes Service
- **Impact** : Moyen (certains utilisateurs affect√©s)
- **Dur√©e** : 45 minutes

## Chronologie
- 14:30 : D√©tection via les alertes de monitoring
- 14:32 : D√©but de l'investigation
- 14:40 : Identification d'un probl√®me de connexion Redis
- 14:45 : Red√©marrage du pod Redis
- 15:15 : R√©solution compl√®te et v√©rification

## Cause racine
Le pod Redis a atteint sa limite de m√©moire et a √©t√© tu√© par le OOM Killer de Kubernetes. La configuration initiale ne pr√©voyait pas suffisamment de m√©moire pour le cache.

## Actions correctives
1. Red√©marrage du pod Redis
2. Augmentation temporaire des limites de m√©moire
3. V√©rification de l'int√©grit√© des donn√©es

## Actions pr√©ventives
1. Augmenter les limites de m√©moire dans la configuration Kubernetes
2. Configurer des alertes pour l'utilisation de la m√©moire
3. Impl√©menter un m√©canisme de cache plus efficace
4. Documenter la proc√©dure de red√©marrage

## Responsables
- **D√©tection** : Syst√®me de monitoring
- **R√©solution** : √âquipe DevOps
- **Communication** : √âquipe Support

## Pi√®ces jointes
- logs/quotes-service-20240115.log
- screenshots/memory-usage.png
```

## 6.6 M√©triques et indicateurs

### 6.6.1 Indicateurs cl√©s de performance (KPI)

| Indicateur                           | Objectif          | Mesure actuelle | Fr√©quence      |
|--------------------------------------|-------------------|-----------------|----------------|
| Disponibilit√© des services           | 99.9%             | 99.8%           | Temps r√©el     |
| Temps de r√©ponse moyen               | < 200ms           | 180ms           | Toutes les 5min|
| Taux d'erreur                        | < 1%              | 0.5%            | Toutes les 5min|
| Utilisation CPU moyenne              | < 70%             | 65%             | Toutes les 5min|
| Utilisation m√©moire moyenne          | < 80%             | 75%             | Toutes les 5min|
| Nombre de requ√™tes par seconde       | -                 | 15 req/s        | Toutes les 5min|
| Temps de r√©cup√©ration apr√®s incident | < 30min           | 25min           | Par incident   |

### 6.6.2 Tableau de bord (√† impl√©menter)

**Options** :

1. **Grafana** : Tableaux de bord personnalisables
2. **Kibana** : Visualisation des logs
3. **Prometheus + Grafana** : Solution compl√®te
4. **Custom dashboard** : Solution maison

**Exemple de configuration Grafana** :

```json
{
  "title": "SAE 5.03 - Overview",
  "panels": [
    {
      "title": "Service Availability",
      "type": "singlestat",
      "targets": [
        {
          "expr": "sum(up{namespace=\"haddock\"}) / count(up{namespace=\"haddock\"}) * 100",
          "format": "time_series",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ]
    },
    {
      "title": "Request Rate",
      "type": "graph",
      "targets": [
        {
          "expr": "sum(rate(http_requests_total{namespace=\"haddock\"}[5m]))",
          "format": "time_series",
          "interval": "",
          "legendFormat": "{{pod}}",
          "refId": "A"
        }
      ]
    }
  ],
  "templating": {
    "list": [
      {
        "name": "namespace",
        "query": "haddock",
        "type": "constant"
      }
    ]
  }
}
```

### 6.6.3 Collecte de m√©triques

#### 6.6.3.1 M√©triques applicatives

```python
# Dans les services Flask
from prometheus_client import make_wsgi_app, Counter, Gauge, Histogram
from werkzeug.middleware.dispatcher import DispatcherMiddleware

# Configuration des m√©triques
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP Requests', ['method', 'endpoint', 'http_status'])
REQUEST_LATENCY = Histogram('http_request_latency_seconds', 'HTTP request latency', ['method', 'endpoint'])
IN_PROGRESS = Gauge('http_requests_in_progress', 'HTTP requests in progress', ['method', 'endpoint'])

# Middleware pour la collecte
def before_request():
    request.start_time = time.time()
    IN_PROGRESS.labels(request.method, request.path).inc()

def after_request(response):
    latency = time.time() - request.start_time
    REQUEST_COUNT.labels(request.method, request.path, response.status_code).inc()
    REQUEST_LATENCY.labels(request.method, request.path).observe(latency)
    IN_PROGRESS.labels(request.method, request.path).dec()
    return response

# Ajout du middleware
app.before_request(before_request)
app.after_request(after_request)

# Exposition des m√©triques
app.wsgi_app = DispatcherMiddleware(app.wsgi_app, {
    '/metrics': make_wsgi_app()
})
```

#### 6.6.3.2 M√©triques syst√®me

```bash
# M√©triques CPU
kubectl top pods -n haddock --containers

# M√©triques m√©moire
kubectl top pods -n haddock --sort-by=memory

# M√©triques r√©seau
kubectl get --raw "/apis/metrics.k8s.io/v1beta1/namespaces/haddock/pods/*/network" | jq .
```

## 6.7 Documentation et proc√©dures

### 6.7.1 Proc√©dures op√©rationnelles

#### 6.7.1.1 Proc√©dure de red√©marrage

```markdown
# Proc√©dure de red√©marrage des services

## Pr√©requis
- Acc√®s √† kubectl
- Permissions suffisantes

## √âtapes

1. **V√©rification de l'√©tat actuel**
   ```bash
   kubectl get pods -n haddock
   ```

2. **Identification du pod √† red√©marrer**

```bash
kubectl get pods -n haddock | grep <service>
```

1. **Red√©marrage du pod**

   ```bash
   kubectl delete pod <nom-du-pod> -n haddock
   ```

2. **V√©rification du red√©marrage**

   ```bash
   kubectl get pods -n haddock -w
   ```

3. **V√©rification des logs**

   ```bash
   kubectl logs <nouveau-pod> -n haddock
   ```

4. **Test fonctionnel**

   ```bash
   curl http://localhost/<service>/health
   ```

## En cas d'√©chec

- V√©rifier les logs
- V√©rifier les ressources disponibles
- Contacter l'√©quipe de support

```txt
#### 6.7.1.2 Proc√©dure de mise √† l'√©chelle

```markdown
# Proc√©dure de mise √† l'√©chelle

## Mise √† l'√©chelle manuelle

1. **V√©rification de la charge actuelle**
   ```bash
   kubectl top pods -n haddock
   ```

2. **Mise √† l'√©chelle**

   ```bash
   kubectl scale deployment <deployment> --replicas=<nombre> -n haddock
   ```

3. **V√©rification**

   ```bash
   kubectl get pods -n haddock
   kubectl get hpa -n haddock
   ```

## Configuration de l'autoscaling

1. **Cr√©ation de l'HPA**

   ```bash
   kubectl autoscale deployment <deployment> --min=<min> --max=<max> --cpu-percent=<pourcentage> -n haddock
   ```

2. **V√©rification**

   ```bash
   kubectl get hpa -n haddock -w
   ```

3. **Ajustement**

   ```bash
   kubectl edit hpa <nom-hpa> -n haddock
   ```

```txt

### 6.7.2 Documentation des incidents

#### 6.7.2.1 Mod√®le de ticket d'incident

```markdown
# Ticket d'incident - [ID]

## Informations g√©n√©rales
- **Date de cr√©ation** : [Date/Heure]
- **Cr√©√© par** : [Nom]
- **Priorit√©** : [Haute/Moyenne/Faible]
- **Service affect√©** : [Nom du service]

## Description
[Description d√©taill√©e du probl√®me]

## Sympt√¥mes
- [Sympt√¥me 1]
- [Sympt√¥me 2]
- [Sympt√¥me 3]

## √âtapes de reproduction
1. [√âtape 1]
2. [√âtape 2]
3. [√âtape 3]

## Impact
- **Utilisateurs affect√©s** : [Nombre/Description]
- **Fonctionnalit√©s affect√©es** : [Liste]
- **S√©v√©rit√©** : [Haute/Moyenne/Faible]

## Investigation
- **Logs pertinents** :
  ```
  [Extraits de logs]
  ```
- **M√©triques** :
  - CPU : [Valeur]%
  - M√©moire : [Valeur]%
  - Temps de r√©ponse : [Valeur]ms

## R√©solution
- **Cause racine** : [Description]
- **Solution appliqu√©e** : [Description]
- **Date de r√©solution** : [Date/Heure]

## V√©rification
- **Tests effectu√©s** : [Liste]
- **R√©sultats** : [Succ√®s/√âchec]
- **Validation** : [Nom de la personne]

## Actions pr√©ventives
1. [Action 1]
2. [Action 2]
3. [Action 3]

## Historique
- [Date/Heure] : [√âv√©nement]
- [Date/Heure] : [√âv√©nement]
- [Date/Heure] : [√âv√©nement]
```

#### 6.7.2.2 Base de connaissances

```markdown
# Base de connaissances - Probl√®mes courants

## 1. Pod en CrashLoopBackOff

### Sympt√¥mes
- Pod red√©marre en boucle
- √âtat "CrashLoopBackOff" dans kubectl get pods

### Causes possibles
- Erreur dans le code de l'application
- Configuration incorrecte
- Ressources insuffisantes
- D√©pendances manquantes

### Solutions
1. **V√©rifier les logs**
   ```bash
   kubectl logs <nom-du-pod> -n haddock --previous
   ```

2. **V√©rifier la configuration**
   ```bash
   kubectl describe pod <nom-du-pod> -n haddock
   ```

3. **Augmenter les ressources**
   ```yaml
   resources:
     limits:
       cpu: "1"
       memory: "512Mi"
     requests:
       cpu: "500m"
       memory: "256Mi"
   ```

4. **Red√©marrer le pod**
   ```bash
   kubectl delete pod <nom-du-pod> -n haddock
   ```

## 2. Probl√®me de connexion Redis

### Sympt√¥mes

- Erreurs "Connection refused" dans les logs
- Services incapables de se connecter √† Redis

### Causes possibles

- Redis non d√©marr√©
- Probl√®me de r√©seau
- Configuration incorrecte

### Solutions

1. **V√©rifier l'√©tat de Redis**
   ```bash
   kubectl get pods -n haddock | grep redis
   ```

2. **Tester la connectivit√©**
   ```bash
   kubectl exec -it <quotes-pod> -n haddock -- ping backend-redis
   ```

3. **V√©rifier la configuration**
   ```bash
   kubectl describe service backend-redis -n haddock
   ```

4. **Red√©marrer Redis**
   ```bash
   kubectl delete pod <redis-pod> -n haddock
   ```

## 3. Performances d√©grad√©es

### Sympt√¥mes

- Temps de r√©ponse √©lev√©s
- Utilisation CPU/M√©moire √©lev√©e
- Requ√™tes timeout

### Causes possibles

- Charge trop importante
- Ressources insuffisantes
- Requ√™tes inefficaces

### Solutions

1. **V√©rifier les m√©triques**

   ```bash
   kubectl top pods -n haddock
   ```

2. **Mettre √† l'√©chelle**
   ```bash
   kubectl scale deployment quotes-service --replicas=3 -n haddock
   ```

3. **Optimiser les requ√™tes**
   - Ajouter des indexes
   - Impl√©menter du caching
   - Optimiser le code

4. **Configurer l'autoscaling**

   ```bash
   kubectl autoscale deployment quotes-service --min=2 --max=5 --cpu-percent=80 -n haddock
   ```

```

## 6.8 Am√©liorations continues

### 6.8.1 Roadmap des am√©liorations

| Am√©lioration                          | Priorit√© | √âch√©ance    | Responsable      | Statut          |
|---------------------------------------|----------|-------------|------------------|-----------------|
| Impl√©mentation de Prometheus/Grafana   | Haute    | Q1 2024     | √âquipe DevOps    | √Ä faire         |
| Configuration de l'autoscaling        | Moyenne  | Q1 2024     | √âquipe DevOps    | En cours        |
| Sauvegardes automatiques Redis         | Haute    | Q1 2024     | √âquipe DevOps    | √Ä faire         |
| Journalisation centralis√©e             | Moyenne  | Q2 2024     | √âquipe DevOps    | Planifi√©        |
| Alertes et notifications               | Haute    | Q1 2024     | √âquipe DevOps    | √Ä faire         |
| Optimisation des performances          | Moyenne  | Q2 2024     | √âquipe Dev       | Planifi√©        |
| Documentation des proc√©dures           | Haute    | Q1 2024     | √âquipe DevOps    | En cours        |

### 6.8.2 Revue post-incident

**Processus** :
1. **Identification** : Analyser l'incident et sa cause racine
2. **Documentation** : R√©diger un rapport d'incident complet
3. **Am√©lioration** : Identifier les actions pr√©ventives
4. **Impl√©mentation** : Mettre en place les correctifs
5. **V√©rification** : Tester les am√©liorations
6. **Documentation** : Mettre √† jour la documentation

**Exemple de revue** :
```markdown
# Revue post-incident - INC-2024-001

## R√©sum√©
- **Incident** : Indisponibilit√© du Quotes Service
- **Date** : 2024-01-15
- **Dur√©e** : 45 minutes
- **Impact** : Moyen

## Cause racine
Limite de m√©moire insuffisante pour le pod Redis, entra√Ænant un OOM kill.

## Le√ßons apprises
1. Les limites de m√©moire doivent √™tre r√©alistes
2. Le monitoring des ressources est crucial
3. Les alertes doivent √™tre configur√©es pour les situations critiques

## Actions correctives
1. ‚úÖ Augmentation des limites de m√©moire pour Redis
2. ‚úÖ Configuration d'alertes pour l'utilisation de la m√©moire
3. ‚úÖ Documentation de la proc√©dure de red√©marrage
4. ‚è≥ Impl√©mentation de l'autoscaling pour Redis
5. ‚è≥ Revue des limites de m√©moire pour tous les services

## Am√©liorations futures
1. Mettre en place un syst√®me de monitoring complet
2. Configurer des alertes proactives
3. Impl√©menter des tests de charge r√©guliers
4. Documenter toutes les proc√©dures d'urgence

## Responsables
- **Revue** : √âquipe DevOps
- **Suivi** : Chef de projet
- **Validation** : Responsable technique
```

### 6.8.3 Indicateurs d'am√©lioration

| Indicateur                          | Cible 2024 | Actuel    | Progression  |
|-------------------------------------|------------|-----------|--------------|
| Temps moyen de r√©solution           | < 30min    | 45min     | üî¥ En retard |
| Disponibilit√© des services          | 99.95%     | 99.8%     | üü° En cours  |
| Couverture des tests                | 90%        | 75%       | üü° En cours  |
| Documentation compl√®te              | 100%       | 80%       | üü° En cours  |
| Temps de r√©ponse moyen              | < 150ms    | 180ms     | üü° En cours  |
| Taux de d√©tection proactive         | 80%        | 40%       | üî¥ En retard |

## 6.9 Conclusion

Le monitoring et la maintenance sont des aspects critiques pour assurer la fiabilit√© et la disponibilit√© de l'application. Les √©l√©ments cl√©s √† retenir sont :

1. **Surveillance proactive** : D√©tecter les probl√®mes avant qu'ils n'affectent les utilisateurs
2. **Journalisation compl√®te** : Avoir des logs d√©taill√©s pour le d√©pannage
3. **Sauvegardes r√©guli√®res** : Prot√©ger contre la perte de donn√©es
4. **Documentation** : Maintenir une documentation √† jour des proc√©dures
5. **Am√©lioration continue** : Apprendre des incidents et am√©liorer constamment

**Recommandations** :

- Impl√©menter un syst√®me de monitoring complet (Prometheus + Grafana)
- Configurer des alertes proactives pour les situations critiques
- Automatiser les sauvegardes et les tests de restauration
- Documenter toutes les proc√©dures op√©rationnelles
- Effectuer des revues r√©guli√®res des incidents et des performances

La mise en place de ces pratiques permettra d'assurer la stabilit√©, la disponibilit√© et la performance de l'application √† long terme.
